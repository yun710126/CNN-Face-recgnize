克里斯蒂安斯齐盖迪	刘薇	杨庆嘉

 

谷歌公司	查珀尔希尔北卡罗来那大学	谷歌公司

 

彼埃尔塞尔曼特	史考特瑞德	德拉莫米尔安吉洛夫	杜米特鲁尔汗

 

谷歌公司	密歇根大学	谷歌公司	谷歌公司

 

文森特万豪克	安得烈拉比诺维奇

 

谷歌公司	谷歌公司

 

 

摘要

 

我们提出了一个深度卷积神经网络结构的代号，它负责在IMANEET大规模视觉识别挑战2014（ILVRC14）中设置用于分类和检测的新的最新状态。这种体系结构的主要特征是改进了网络内的计算资源的利用。这是通过精心设计的设计实现的，它允许在保持计算预算不变的同时增加网络的深度和宽度。为了优化质量，建筑决策是基于HebBand原理和多尺度处理的直觉。在我们提交的ILVRC14中使用的一个特定化身被称为GoGoLett，一个22层深度网络，其质量在分类和检测的上下文中被评估。

1	介绍

 

在过去的三年中，主要是由于深度学习的进步，更具体的卷积网络。十图像识别和目标检测的质量一直在飞速发展。一个令人振奋的消息是，大部分的进步不仅仅是由于更强大的硬件、更大的数据集和更大的模型的结果，而是主要是新思想、算法和改进的网络架构的结果。例如，除了用于检测的相同比赛的分类数据集之外，ILSVRC 2014比赛的顶级参赛者没有使用新的数据源。我们的GoogLeNet提交到ILVRC 2014实际上使用了12个参数比Kryjevs等人等的获胜架构更少。9两年前，虽然明显更准确。在目标检测中，最大的收获不是来自于单独使用深层网络或者更大的模型，而是来自于深层架构和经典计算机视觉的协同作用，比如Girshick等人的R-CNN算法。6]

 

另一个值得注意的因素是，随着移动和嵌入式计算的不断发展，我们算法的效率——尤其是它们的功率和内存使用——变得更加重要。值得注意的是，导致本文所提出的深层架构设计的考虑因素包括这个因素，而不是完全固定在精度数字上。对于大多数实验，这些模型被设计成在推理时保持15亿乘法加法运算的预算，这样它们就不会成为纯粹的学术好奇心，而是可以以合理的成本投入现实世界的使用，甚至在大型数据集上。

 



 

1



 

在本文中，我们将重点介绍一种有效的用于计算机视觉的深层神经网络体系结构，代号为Inception，它来源于Lin等人的网络论文中的网络。十二结合著名的“我们需要更深”的网络迷1]在我们的例子中，“深度”一词有两种不同的含义：首先，我们以“初始模块”的形式引入新的组织级别，以及更直接的增加网络深度的意义。一般来说，可以将初始模型视为逻辑顶点。十二在阿罗拉等理论工作的启发和指导下2]该体系结构的优点在ILSVRC 2014分类和检测挑战上得到了实验验证，在ILSVRC 2014分类和检测挑战上，它的性能显著优于当前最新技术。

 

2	相关工作

 

从LeNET-5开始十卷积神经网络(CNN)通常具有标准结构——堆叠的卷积层(可选地随后是对比度归一化和最大池)之后是一个或多个完全连接的层。这种基本设计的变体在图像分类文献中很普遍，并且在MNIST、CIFAR以及最显著的ImageNet分类挑战中产生了迄今为止最好的结果。9，二十一]对于像IMANET这样的更大的数据集，最近的趋势是增加层数。十二和层大小二十一，十四在使用辍学者的时候7为了解决过度拟合的问题。

 

尽管担心最大汇聚层导致精确空间信息的丢失，但是与9也已成功地用于本地化。9，十四对象检测6,十四,十八,五人体姿势估计十九]灵感来自神经科学 灵长类视觉皮层模型，Serre等。[十五使用一系列不同大小的固定Gabor滤波器来处理多个尺度，类似于初始模型。然而，与固定的2层深模型相反。十五在初始模型中所有的滤波器都被学习了。此外，开始层重复了很多次，在GoGoLeNET模型的情况下导致了22层深度模型。

 

网络中的网络是林等人提出的一种方法。[十二为了提高神经网络的代表性功率。当应用于卷积层时，该方法可以被看作附加的1 1个卷积层，然后通常是整流线性激活。9]这使得它能够容易地集成在当前的美国有线电视新闻网管道中。我们在我们的架构中使用了这种方法。然而，在我们的设置中，1 1个卷积具有双重用途：最关键的是，它们主要用作降维模块，以消除计算瓶颈，否则将限制我们网络的大小。这不仅允许增加深度，而且允许我们的网络的宽度没有显著的性能损失。

 

当前主要的目标检测方法是Girshick等人提出的具有卷积神经网络的区域（R-CNN）。[6]R-CNN将整个检测问题分解为两个子问题：首先以类别不可知的方式利用诸如颜色和超像素一致性之类的低级线索对潜在的对象建议进行分类，然后使用CNN分类器来识别这些位置的对象类别。这种两阶段方法利用了具有低级线索的包围盒分割的精确性，以及现有CNN强大的分类能力。我们在我们的检测提交中采用了类似的流水线，但是在两个阶段，如多个BOX中都有增强功能。5预测更高的目标包围盒召回，以及更好的分类边界框建议的集成方法。

 

3	动机与高层次考虑

 

提高深度神经网络性能的最直接的方法是增加它们的大小。这包括增加网络的深度——级别的数量——及其宽度：每个级别的单元数量。这是训练更高质量模型的一种简单而安全的方法，特别是考虑到大量标记训练数据的可用性。然而，这个简单的解决方案有两个主要缺点。

 

较大的尺寸通常意味着较多的参数，这使得扩大的网络更容易过拟合，特别是在训练集中的标记示例数量有限的情况下。这可能成为一个主要的瓶颈，因为创建高质量的培训集可能是棘手的。



 

2



![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B5E.tmp.png) 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

（a）西伯利亚哈士奇犬	（b）爱斯基摩犬

 

图1：来自ILSRC 2014分类挑战的1000个类的两个不同的类。

 

 

以及昂贵，特别是如果需要专家人工评分器来区分像ImageNet中的细粒度视觉类别（甚至在1000类ILSVRC子集中），如图1所示。

 

网络规模的均匀增加的另一个缺点是计算机资源的使用急剧增加。例如，在深视觉网络中，如果两个卷积层是链式的，那么它们的滤波器数量的任何均匀增加都会导致计算的二次增加。如果增加的容量被低效率地使用（例如，如果大多数权重最终接近于零），那么大量计算被浪费。由于在实践中，计算预算总是有限的，所以即使主要目标是提高结果的质量，计算资源的有效分配也优于不加区别地增加大小。

 

解决这两个问题的基本方法是最终从完全连接的体系结构转移到稀疏连接的体系结构，甚至在卷积内部。除了模拟生物系统之外，由于Arora等人的开创性工作，这也具有更坚实的理论基础的优势。[2]他们的主要结果是，如果数据集的概率分布可以用一个大的、非常稀疏的深层神经网络来表示，那么可以通过分析最后一层激活和聚类的相关统计量来逐层构造最优网络拓扑。具有高度相关输出的神经元。虽然严格的数学证明需要非常严格的条件，但事实是，这个陈述与赫比原理——神经元一起燃烧，连接在一起——产生共鸣，这表明，即使在不那么严格的条件下，在实践中，基本思想也是适用的。

 

在不利的方面，今天的计算基础设施对于非均匀稀疏数据结构的数值计算是非常低效的。即使算术运算的数量减少了100，查找和高速缓存未命中的开销也占主导地位，切换到稀疏矩阵不会得到回报。通过使用稳定改进的、高度调谐的数值库，允许更快速的密集矩阵乘法，利用底层CPU或GPU硬件的微小细节，从而进一步扩大了间隙。十六，9]此外，非均匀稀疏模型需要更复杂的工程和计算基础设施。当前大多数面向视觉的机器学习系统仅仅通过利用电磁卷积在空间域中利用稀疏性。然而，卷积被实现为密集连接到早期层中的补丁的集合。传统上，在特征维度上，CuNETs使用随机和稀疏连接表。十一为了打破对称性，提高学习，趋势变回完全连接。9为了更好地优化并行计算。结构的均匀性和大量的滤波器以及更大的批量大小允许使用高效的密集计算。

 

这就提出了一个问题，是否还有希望进行下一个中间步骤：一个利用额外稀疏性的体系结构，即使在过滤级别上，正如理论所建议的，但是利用了



 

3



 

当前的硬件利用密集矩阵的计算。关于稀疏矩阵计算的大量文献（例如）3_1_提出将稀疏矩阵聚类到相对密集的子矩阵中趋向于给出稀疏矩阵乘法的现有实用性能。在不久的将来，类似的方法将被用于自动化构建非均匀的深层学习体系结构，这似乎并不牵强。

 

Inception体系结构最初是作为第一个作者的案例研究开始的，该作者评估了复杂的网络拓扑构造算法的假设输出，该算法试图近似[1]所暗示的稀疏结构。2用于视觉网络，并通过密集、易读的组件覆盖虚拟结果。尽管是一项高度推测性的工作，但只有在对拓扑的确切选择进行两次迭代之后，我们才能够看到相对于基于十二]在进一步调整学习速率、超参数以及改进的训练方法之后，我们建立了所得到的Inception体系结构在定位和目标检测的上下文中特别有用，作为用于6[和]5]有趣的是，尽管大多数原始体系结构选择都经过了彻底的质疑和测试，但最终证明它们至少是局部最优的。

 

然而，我们必须谨慎：尽管所提出的体系结构已经成功地用于计算机视觉，但是它的质量是否可以归因于导致其构建的指导原则仍然是令人怀疑的。确保将要求更彻底的分析和验证：例如，如果基于下面描述的原理的自动化工具将发现类似的、但是更好的视觉网络拓扑。最令人信服的证据是，如果一个自动化系统使用相同的算法创建网络拓扑，但是在其他领域使用看起来非常不同的全局体系结构，从而获得类似的收益。至少，Inception架构的初步成功为今后在这个方向上令人兴奋的工作提供了坚实的动力。

 

4	建筑细部

 

Inception架构的主要思想是发现如何用容易获得的密集组件来近似和覆盖卷积视觉网络中的最优局部稀疏结构。请注意，假设翻译不变性意味着我们的网络将建立卷积积木。我们所需要的是找到最佳的局部构造并在空间上重复它。阿罗拉等人。[2建议逐层构造，其中应分析最后一层的相关性统计并将它们聚类为具有高相关性的单元组。这些簇形成下一层的单元，并连接到前一层中的单元。我们假设来自较早层的每个单元对应于输入图像的某个区域，并且这些单元被分组到滤波器组中。在较低层（接近输入的）中，相关单元将集中在局部区域。这意味着，我们将以集中于单个区域中的大量团簇而告终，并且它们可以被下一层中的1 1个卷积层覆盖，正如十二]然而，人们还可以预期，在较大的块上卷积可以覆盖的更小数量的在空间上分布更广的簇，并且在越来越大的区域上斑块的数量将会减少。为了避免补丁对齐问题，Inception架构的当前体现被限制为过滤器大小1 1、3 3和5 5，但是这个决定更多地基于方便而不是必要。它还意味着建议的体系结构是所有这些层及其输出滤波器组的组合，这些层级联成单个输出向量，形成下一阶段的输入。此外，由于汇集操作对于当前现有技术的卷积网络的成功至关重要，因此它建议在每个这样的阶段中添加备选的并行汇集路径也应具有额外的有益效果(参见图2(a))。

 

由于这些“初始模块”相互叠加，它们的输出相关统计量必然会变化：由于较高抽象的特征被较高层捕获，它们的空间集中度预计会降低，这表明3 3卷积和5 5卷积的比例应该当我们移动到更高的层时会增加。

 

上述模块的一个大问题，至少在这种NA形式中是，即使在5个5卷积的适度数量上，在具有大量滤波器的卷积层的顶部也可能是昂贵的。一旦汇集单元被添加到混合中，这个问题就变得更加明显：它们的输出滤波器的数量等于前一阶段的滤波器数目。汇集层的输出与卷积层的输出的合并将导致不可避免的。



 

4



![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B5F.tmp.png) 

 

|                       |                             |         |           | 滤波器  |         |           |      |
| --------------------- | --------------------------- | ------- | --------- | ------- | ------- | --------- | ---- |
|                       | 滤波器                      |         |           | 级联    |         |           |      |
|                       | 级联                        |         |           |         |         |           |      |
|                       |                             |         |           | 3x3卷积 | 5x5卷积 | 1x1卷积   |      |
| 1x1卷积               | 3x3卷积                     | 5x5卷积 | 3x3最大池 | 1x1卷积 |         |           |      |
|                       |                             |         |           |         |         |           |      |
|                       |                             |         |           | 1x1卷积 | 1x1卷积 | 3x3最大池 |      |
|                       | 前一层                      |         |           | 前一层  |         |           |      |
| （a）起始模块，NA版本 | （b）具有维度缩减的起始模块 |         |           |         |         |           |      |

![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B70.tmp.png)![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B71.tmp.png)![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B72.tmp.png)![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B73.tmp.png)![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B84.tmp.png) 

 

图2：初始模块

 

 

从一个阶段到另一个阶段增加产出的数量。即使这种体系结构可能覆盖了最优的稀疏结构，但它的效率也会非常低，从而导致在几个阶段内出现计算爆炸。

 

这引出了所提议体系结构的第二个想法：明智地应用维度缩减和投影，否则计算需求将增加太多。这是基于嵌入的成功：即使是低维嵌入也可能包含大量关于相对大的图像补丁的信息。然而，嵌入以密集、压缩的形式表示信息，压缩的信息更难建模。我们希望保持我们的代表在大多数地方稀疏（根据条件）2）只有在必须集合信号时才压缩信号。也就是说，使用1个1个卷积来计算在昂贵的3个3和5个5卷积之前的减少。除了用作还原，它们还包括使用整流线性激活，使它们成为双重用途。最后的结果如图2（b）所示。

 

一般来说，初始网络是由相互堆叠的上述类型的模块组成的网络，偶尔使用具有步长2的最大池层来将网格的分辨率减半。由于技术原因（训练期间的内存效率），开始仅在较高层使用Inception模块，同时以传统卷积方式保持较低层似乎是有益的。这不是严格必要的，只是反映了我们当前实施中一些基础设施的低效性。

 

这种体系结构的主要优点之一是，它允许显著增加每个阶段的单元数量，而不会在计算复杂度方面出现不受控制的爆炸。降维的普遍使用允许将最后一级的大量输入滤波器屏蔽到下一层，首先降低它们的维数，然后用大的补丁大小卷绕它们。这种设计的另一个实际有用的方面是，它符合这样的直觉，即视觉信息应当以各种比例进行处理，然后进行聚合，以便下一阶段能够同时从不同比例提取特征。

 

计算资源的改进使用允许在不陷入计算困难的情况下增加每个阶段的宽度以及阶段的数量。利用初始架构的另一种方法是创建稍差但计算成本更低的版本。我们发现，所有包括的旋钮和杠杆都允许计算资源的受控平衡，这可能导致网络比具有非初始体系结构的相似执行网络快2 3，然而这需要此时仔细的手工设计。

 

5	谷歌网

 

在ILVRC14比赛中，我们选择了GoogLeNet作为我们的团队名称。这个名字是对延安-莱克森开创LeNET 5网络的敬意[十]我们还使用GoogLeNet来指代在竞赛提交中使用的Inception体系结构的具体体现。我们还使用了更深更广的Inception网络，其质量稍逊一筹，但将其添加到集成似乎略微改善了结果。我们省略了该网络的细节，因为我们的实验已经表明，确切的建筑参数的影响是相对的。



 

5



 

| 类型          | 贴片尺寸 | 输出        | 深度 | ^ ^ 1      |      | 1          | ^ ^ 3 3 3  | ^ ^ ~3     |        | 3          | ^ ^～5 5 | ^ ^ ~5     |       | 5     | 水塘 | 帕拉姆 | 操作系统 |      |
| ------------- | -------- | ----------- | ---- | ---------- | ---- | ---------- | ---------- | ---------- | ------ | ---------- | -------- | ---------- | ----- | ----- | ---- | ------ | -------- | ---- |
| 步幅          | 大小     |             |      | 减少       |      |            | 减少       |            |        | PROJ       |          |            |       |       |      |        |          |      |
|               |          |             |      |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 卷积          | 7 7＝2   | 112 112 112 | 1    |            |      |            |            |            |        |            |          |            |       |       |      | 2.7K   | 34m      |      |
| 最大池        | 3 3＝2   | 56 56 56    | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 卷积          | 3 3＝1   | 56 56 56    | 2    |            |      |            | 六十四     | 一百九十二 |        |            |          |            |       |       | 112K | 360米  |          |      |
| 最大池        | 3 3＝2   | 28 28 28    | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 创始（3A）    |          | 28 28 28    | 2    | 六十四     |      | 九十六     | 一百二十八 |            | 十六   | 三十二     |          | 三十二     | 159K  | 128米 |      |        |          |      |
| 创始（3b）    |          | 28 28 28    | 2    | 一百二十八 |      | 一百二十八 | 一百九十二 |            | 三十二 | 九十六     |          | 六十四     | 380K  | 304m  |      |        |          |      |
| 最大池        | 3 3＝2   | 14 14 14    | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 起始（4A）    |          | 14 14 14    | 2    | 一百九十二 |      | 九十六     | 二百零八   |            | 十六   | 四十八     |          | 六十四     | 364K  | 73米  |      |        |          |      |
| 起始（4b）    |          | 14 14 14    | 2    | 一百六十   |      | 一百一十二 | 二百二十四 |            | 二十四 | 六十四     |          | 六十四     | 437 K | 88米  |      |        |          |      |
| 起始（4C）    |          | 14 14 14    | 2    | 一百二十八 |      | 一百二十八 | 二百五十六 |            | 二十四 | 六十四     |          | 六十四     | 463K  | 100米 |      |        |          |      |
| 起始（4D）    |          | 14 14 14    | 2    | 一百一十二 |      | 一百四十四 | 二百八十八 |            | 三十二 | 六十四     |          | 六十四     | 580K  | 119米 |      |        |          |      |
| 起始（4E）    |          | 14 14 14    | 2    | 二百五十六 |      | 一百六十   | 三百二十   |            | 三十二 | 一百二十八 |          | 一百二十八 | 840K  | 170米 |      |        |          |      |
| 最大池        | 3 3＝2   | 7 7 7       | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 成立（5A）    |          | 7 7 7       | 2    | 二百五十六 |      | 一百六十   | 三百二十   |            | 三十二 | 一百二十八 |          | 一百二十八 | 1072K | 54米  |      |        |          |      |
| 开始（5B）    |          | 7 7 7       | 2    | 三百八十四 |      | 一百九十二 | 三百八十四 |            | 四十八 | 一百二十八 |          | 一百二十八 | 138K  | 71米  |      |        |          |      |
| AVG池         | 7 7＝1   | 1 1 1       | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 辍学（40~3i） |          | 1 1 1       | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |
| 线性的        |          | 1 1 1       | 1    |            |      |            |            |            |        |            |          |            |       |       |      | 1000 K | 1m       |      |
| 软最大值      |          | 1 1 1       | 0    |            |      |            |            |            |        |            |          |            |       |       |      |        |          |      |

 

表1：初始架构的GoGoLeNe化身

 

 

未成年人。这里，最成功的特定实例（命名为GoogLeNet）在表1中描述用于演示目的。完全相同的拓扑结构（用不同的采样方法训练）被用于我们的集合中的7个模型中的6个。

 

所有的卷积，包括在起始模块内部的卷积，都使用整流线性激活。在我们的网络中，接收域的大小是224，RGB颜色通道的平均减法为224。“_^~3缩减”和“_^~5缩减”表示在3 3和5 5卷积之前使用的缩减层中的1 1个滤波器的数目。在池PROJ列中内置的最大池之后，可以看到PRO喷射层中1个1个过滤器的数量。所有这些还原层~2A投影层也采用整流线性激活。

 

该网络的设计考虑到了计算效率和实用性，使得推理可以在单个设备上运行，甚至包括那些计算资源有限的设备，尤其是具有低内存占用的设备。当仅计算具有参数的层（或者如果我们还计算池）的27层时，网络是22层深度的。用于网络构建的层（独立构建块）的总数量约为100。然而，这个数目取决于所使用的机器学习基础设施系统。在分类器之前使用平均池是基于十二虽然我们的实现不同，但是我们使用一个额外的线性层。这使得我们能够容易地调整并微调我们的网络以适应其他标签集，但它大多是方便的，并且我们并不期望它产生大的影响。结果发现，从全连接层移动到平均汇聚使Top-1精度提高了约0.6%，但是即使在移除全连接层之后，辍学的使用仍然是必要的。

 

鉴于网络的深度相对较大，以有效方式将梯度传播回所有层的能力令人担忧。一个有趣的见解是，相对浅层网络在这个任务上的强大性能表明网络中间层产生的特征应该非常具有区分性。通过增加连接到这些中间层的辅助分类器，我们希望在分类器的较低阶段鼓励区分，增加被传回的梯度信号，并提供额外的正则化。这些分类器采取放在初始（4a）和（4d）模块的输出之上的较小卷积网络的形式。在训练过程中，它们的损失以折扣权重被加到网络的总损失中（辅助分类器的损失被加权0.3）。在推理时间，这些辅助网络被丢弃。

 

侧边的额外网络的精确结构，包括辅助分类器，如下：

 

• 平均汇聚层，具有5 5个滤波器尺寸和步长3，导致(4a)输出4 4 512，而(4d)级输出4 4 528。



 

6



![img](file:///C:\Users\wang\AppData\Local\Temp\ksohtml\wps3B94.tmp.png) 

|                  |                  | 软Max 2          |                  |                  |                  |                  |                  |          |      |      |      |
| ---------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- | -------- | ---- | ---- | ---- |
|                  | 软最大激活       |                  |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  | 常设费用         |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  | 平均池           |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  | 7x7~（~^）1（V） |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  | 迪斯康塔特       |                  |                  |                  |                  |                  |          |      |      |      |
| 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  | 卷积和多项式相乘 |                  |                  |                  |          |      |      |      |
| 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |                  |                  |                  |          |      |      |      |
|                  | 卷积和多项式相乘 | 卷积和多项式相乘 |                  | 马克斯普尔       |                  |                  |                  |          |      |      |      |
|                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  |                  |                  |                  |                  |          |      |      |      |
|                  |                  | 迪斯康塔特       |                  |                  |                  |                  |                  |          |      |      |      |
| 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  | 卷积和多项式相乘 |                  |                  | 软Max            |          |      |      |      |
| 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |                  |                  |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  |                  |                  |          |      |      |      |
|                  | 卷积和多项式相乘 | 卷积和多项式相乘 |                  | 马克斯普尔       | 软最大激活       |                  |                  |          |      |      |      |
|                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  |                  |                  |                  |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  |                  | 马克斯普尔       |                  |                  |                  |                  | 常设费用 |      |      |      |
|                  |                  |                  | 3x3~^ ^ 2（s）   |                  |                  |                  |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  | 迪斯康塔特       |                  |                  |                  |                  | 常设费用         |          |      |      |      |
|                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  |                  |          |      |      |      |
| 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    |                  |                  |                  |          |      |      |      |
|                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 马克斯普尔       | 平均池           |                  |                  |          |      |      |      |
|                  |                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~^ ^ 3（V）   |                  |                  |          |      |      |      |
|                  |                  |                  | 迪斯康塔特       |                  |                  |                  |                  |          |      |      |      |
|                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  |                  |                  |          |      |      |      |
|                  | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |                  |                  |          |      |      |      |
|                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 马克斯普尔       |                  |                  |          |      |      |      |
|                  |                  |                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  |                  |                  |          |      |      |      |
|                  |                  |                  | 迪斯康塔特       |                  |                  |                  |                  | 软Max 0  |      |      |      |
|                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  | 软最大激活       |                  |          |      |      |      |
|                  | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |                  |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 马克斯普尔       |                  | 常设费用         |          |      |      |      |
|                  |                  |                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  |                  |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  |                  |                  |          |      |      |      |
|                  |                  |                  |                  | 迪斯康塔特       |                  |                  |                  | 常设费用 |      |      |      |
|                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |          |      |      |      |
|                  |                  | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    |                  |          |      |      |      |
|                  |                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 马克斯普尔       | 平均池           |          |      |      |      |
|                  |                  |                  |                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~^ ^ 3（V）   |          |      |      |      |
|                  |                  |                  |                  |                  |                  | 迪斯康塔特       |                  |          |      |      |      |
|                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  |          |      |      |      |
|                  |                  |                  | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |          |      |      |      |
|                  |                  |                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 马克斯普尔       |          |      |      |      |
|                  |                  |                  |                  |                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  |          |      |      |      |
|                  |                  |                  |                  |                  |                  | 马克斯普尔       |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  | 3x3~^ ^ 2（s）   |                  |          |      |      |      |
|                  |                  |                  |                  |                  |                  | 迪斯康塔特       |                  |          |      |      |      |
|                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  |          |      |      |      |
|                  |                  |                  | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |          |      |      |      |
|                  |                  |                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 马克斯普尔       |          |      |      |      |
|                  |                  |                  |                  |                  | 1x1~~^ 1（S）    | 1x1~~^ 1（S）    | 3x3~（^）1（S）  |          |      |      |      |
|                  |                  |                  |                  |                  |                  | 迪斯康塔特       |                  |          |      |      |      |
|                  |                  |                  | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 | 卷积和多项式相乘 |                  |          |      |      |      |
|                  |                  |                  | 1x1~~^ 1（S）    | 3x3~（^）1（S）  | 5x5~~^ 1（S）    | 1x1~~^ 1（S）    |                  |          |      |      |      |

 

卷积和多项式相乘	卷积和多项式相乘	马克斯普尔

 

1x1~~^ 1（S）	1x1~~^ 1（S）	3x3~（^）1（S）

 

马克斯普尔

 

3x3~^ ^ 2（s）

 

局部规范

 

卷积和多项式相乘

 

3x3~（^）1（S）

 

卷积和多项式相乘

 

1x1~~^ 1（V）

 

局部规范

 

马克斯普尔

 

3x3~^ ^ 2（s）

 

卷积和多项式相乘

 

7x7~（^）^ 2（s）

 

输入

 

图3：GoGoLeNET网络与所有的铃声和口哨



 

 

7



 

• 1维1卷积与128个滤波器的降维和整流线性激活。

 

• 全连接层1024单位和整流线性激活。

 

• 辍学层与输出下降的70~3i比。

 

• 以SOFTMax损失作为分类器的线性层（预测相同的1000类作为主分类器，但在推理时间被删除）。

 

图3描述了所得到的网络的示意图。

 

6	训练方法论

 

我们的网络是使用DistStruts训练的。4利用模型和数据并行的分布式机器学习系统。虽然我们只使用基于CPU的实现，粗略的估计表明GoGoLeNET网络可以在一周内使用很少的高端GPU来训练以收敛，主要限制是内存使用。我们的训练使用了具有0.9动量的异步随机梯度下降法。十七固定学习速率表（每8个周期将学习速率降低4~3i）。波亚克平均值十三用于创建在推理时间使用的最终模型。

 

我们的图像采样方法在过去的几个月里发生了很大的变化，已经融合的模型被用其他选项来训练，有时与变化的超参数结合，比如辍学和学习率，因此很难对TH给出明确的指导。最有效的单一方式来训练这些网络。更复杂的是，一些模型主要是在较小的相对作物上进行训练，而另一些则是在较大的作物上进行训练。8]尽管如此，在竞争之后被证实非常有效的一个处方包括取样图像的不同大小的块，其大小均匀地分布在图像区域的8%~3%~3之间，并且其纵横比在3=4和4=3之间随机选择。此外，我们发现安德鲁霍华德的光度畸变。8有助于在一定程度上克服过度拟合。此外，我们开始使用随机插值方法（双线性，面积，最近邻和立方体，以等概率）调整相对较晚的大小，并结合其他超参数变化，所以我们不能确定最终结果是否受到t继承人使用。

 

7	ILVRC 2014分类挑战设置和结果

 

ILSVRC 2014分类挑战包括将图像分类为Imagenet层次结构中的1000个叶节点类别之一。大约有120万个图像用于训练，50000个用于验证，100000个图像用于测试。每个图像与一个地面真值类别相关联，并且基于最高得分分类器预测来测量性能。通常报告两个数字：Top-1准确率，它比较地面真值与第一预测类；Top-5错误率，它比较地面真值与第五预测类：如果地面真值位于顶部，则认为图像被正确分类。- 5，无论其排名如何。该挑战使用排名前5的错误率进行排序。

 

我们参加了挑战，没有外部数据用于培训。除了本文所述的训练技术之外，我们在测试过程中采用了一套技术来获得更高的性能，我们将在下面详细阐述。

 

\1. 我们独立训练了7个版本的相同的GoogLeNet模型（包括一个更宽的版本），并用它们进行集合预测。这些模型用相同的初始化（即使具有相同的初始权重，主要是由于疏忽）和学习速率策略来训练，并且它们在采样方法和它们看到输入图像的随机顺序上仅不同。

 

\2. 在测试过程中，我们采用了比KRiZevSkyet等更具侵略性的种植方式。[9]具体来说，我们将图像调整为4个尺度，其中较短的维度（高度或宽度）分别为256, 288, 320和352，取这些大小的图像的左、中、右方（在肖像图像的情况下，我们取顶部、中心和底部正方形）。对于每一个正方形，我们取4个角和中心224个224个作物以及



 

8



 

|        | 团队     |            | 年           | 地点          | 错误（前5） | 使用外部数据 |              |           |      |      |      |
| ------ | -------- | ---------- | ------------ | ------------- | ----------- | ------------ | ------------ | --------- | ---- | ---- | ---- |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | 监督     |            | 二千零一十二 | 第一          | 16:4~~3:    |              | 不           |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | 监督     |            | 二千零一十二 | 第一          | 15∶3~3      |              | Imagenet 22K |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | 克拉丽菲 |            | 二千零一十三 | 第一          | 11:7~~3~    |              | 不           |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | 克拉丽菲 |            | 二千零一十三 | 第一          | 11:2~~3~    |              | Imagenet 22K |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | MSRA     |            | 二千零一十四 | 第三          | 7:35~3~     |              | 不           |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | VGG      |            | 二千零一十四 | 第二          | 7:32～~3    |              | 不           |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        | 谷歌网   |            | 二千零一十四 | 第一          | 6:67～~3    |              | 不           |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
|        |          |            |              | 表2：分类性能 |             |              |              |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 模型数 |          | 农作物数量 | 成本         | Top-5错误     | 与基地相比  |              |              |           |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 1      |          |            | 1            |               |             | 1            | 10:07~~3     | 基础      |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 1      |          |            | 十           |               |             | 十           | 9:15~~3~     | -0.92~~3  |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 1      |          |            | 一百四十四   |               |             | 一百四十四   | 7:89~~3~     | -2.18~~3  |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 7      |          |            | 1            |               |             | 7            | 8:09~~3      | -1.98~~3i |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 7      |          |            | 十           |               |             | 七十         | 7:62~~3~     | -2.45～~3 |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |
| 7      |          |            | 一百四十四   |               |             | 一千零八     | 6:67～~3     | -3.45～~3 |      |      |      |
|        |          |            |              |               |             |              |              |           |      |      |      |

 

表3：GoGoLeNET分类性能崩溃

 

 

平方大小调整为224×224，以及镜像版本。这导致每幅图像中有4个3、6个2个、144个作物。安德鲁霍华德使用了类似的方法。8在上一年的条目中，我们的经验验证比所提出的方案稍差。我们注意到，在实际应用中，这种积极的种植可能是不必要的，因为在合理数量的作物出现后，更多作物的效益将变得微不足道（正如我们稍后将要展示的）。

 

\3. SOFTMax概率在多个作物和所有个体CLAS SIMSER上进行平均，以获得最终预测。在我们的实验中，我们分析了在验证数据上的替代方法，例如作物上的最大池和分类器的平均值，但是它们比简单的平均化导致了较差的性能。

 

在本文的其余部分，我们分析了多因素，有助于最终提交的整体性能。

 

我们在挑战中的最终提交在验证和测试数据上都获得了6.67%的前5位错误，在其他参与者中排名第一。这与2012年的SuperVision方法相比，相对减少了56.5%，与前一年的最佳方法（Clarifai）相比，相对减少了约40%，这两种方法都使用外部数据来训练分类器。下表显示了一些表现最出色的方法的统计数据。

 

我们还通过改变模型数量和在下表中预测图像时使用的作物数量，来分析和报告多个测试选择的性能。当我们使用一个模型时，我们选择在验证数据上具有最低的Top-1错误率的模型。所有数据都在验证数据集上报告，以便不超出测试数据统计。

 

8	ILVRC 2014检测挑战设置和结果

 

ILVRSC检测任务是在200个可能的类中在图像中产生包围盒。如果检测到的对象匹配基本事实的类，并且它们的边界框重叠至少50%（使用Jaccard索引），则它们计数正确。外来检测计数为假阳性并被处罚。与分类任务相反，每个图像可能包含



 

9



 

| 团队               | 年           |      | 地点    | 地图     | 外部数据      | 系综     | 方法               |      |      |      |      |
| ------------------ | ------------ | ---- | ------- | -------- | ------------- | -------- | ------------------ | ---- | ---- | ---- | ---- |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
| 尤瓦               | 二千零一十三 |      | 第一    | 22:6~~3~ | 没有人        | ?        | 费希尔矢量         |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
| 深度洞察力         | 二千零一十四 |      | 第三    | 40:5~~3  | ImageNet 1K   | 3        | 美国有线电视新闻网 |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
| 香港中文大学深渊网 | 二千零一十四 |      | 第二    | 40:7~~3  | ImageNet 1K   | ?        | 美国有线电视新闻网 |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
| 谷歌网             | 二千零一十四 |      | 第一    | 43:9~~3  | ImageNet 1K   | 6        | 美国有线电视新闻网 |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    |              |      |         |          | 表4：检测性能 |          |                    |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 团队         |      |         |          | 地图          | 语境模型 | 边界盒回归         |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 修剪         |      |         | 31:6S~3~ |               | 不       |                    | ?    |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 伯克利视觉   |      |         | 34∶5~~3  |               | 不       |                    | 对   |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 尤瓦         |      |         | 35:4~~3  |               | ?        |                    | ?    |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 香港中文大学 |      | 37∶7~~3 |          | 不            |          | ?                  |      |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 谷歌网       |      |         | 38∶02~~3 |               | 不       |                    | 不   |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |
|                    | 深度洞察力   |      |         | 40:2~~3~ |               | 对       |                    | 对   |      |      |      |
|                    |              |      |         |          |               |          |                    |      |      |      |      |

 

表5：单模型检测性能

 

 

许多物体或没有物体，它们的尺度可以从大到小不等。使用平均平均精度（MAP）报告结果。

 

GoogLeNet所采取的检测方法与R-CNN相似。6但是，使用初始模型作为区域分类器来增强。此外，通过结合选择性搜索提高了区域建议步骤。二十“多箱法”5预测更高的目标包围盒回忆。为了减少假阳性的数量，超像素尺寸增加了2。这使得来自选择性搜索算法的建议减半。我们增加了来自多箱的200个地区提案。5[结果]总计约为60[~3]；6同时，将覆盖范围从92~3i增加到93~3i。随着覆盖范围的增加，削减建议数量的总体效果是单个模型情况下平均精度提高了1~3。最后，在对每个区域进行分类时，使用6个集合的集合，将结果从40~3i提高到43.9~3i精度。注意，与R-CNN相反，我们没有使用边界框回归，由于时间的缺乏。

 

我们首先报告顶部检测结果，并显示了从检测任务的第一版以来的进展。与2013的结果相比，准确度几乎翻了一番。最优秀的团队都使用卷积网络。我们报告表4中的官方分数和每个团队的共同策略：使用外部数据、集成模型或上下文模型。外部数据通常是ILSVRC12分类数据，用于对稍后对检测数据进行细化的模型进行预训练。一些团队还提到了本地化数据的使用。由于定位任务边界框的很大一部分不包括在检测数据集中，因此可以使用该数据对通用边界框回归器进行预训练，就像使用分类进行预训练一样。GoGoLeNT条目没有使用本地化数据进行预训练。

 

在表5中，我们仅使用单个模型比较结果。性能最好的模型是Deep Insight，令人惊讶的是，只有3个模型的集成提高了0.3点，而GoogLeNet通过集成获得了显著更强的结果。

 

9	结论

 

我们的结果似乎提供了坚实的证据，即通过易于获得的密集构建块来逼近期望的最佳稀疏结构是改进用于计算机视觉的神经网络的可行方法。这种方法的主要优点是，与较浅和较窄的网络相比，在计算要求适度增加的情况下，显著的质量增益。还要注意，我们的检测工作是有竞争力的，尽管既不利用上下文也不执行边界框。



 

十



 

回归和这一事实提供了进一步的证据的强度开始架构。虽然期望通过更昂贵的相似深度和宽度的网络可以获得类似的结果质量，但我们的方法提供了可靠的证据，证明移动到更稀疏的体系结构是可行和有用的。这预示着基于自动化的方法，以自动化的方式创造出更精巧、更精细的结构。2]

 

十	致谢

 

我们要感谢Sanjeev Arora和Aditya Bhaskara进行了卓有成效的讨论。2]我们也很感激这种怀疑。4他们特别支持Rajat Monga、Jon Shlens、Alex Krizhevsky、Jeff Dean、Ilya Sutskever和Andrea Frome。我们还要感谢Tom Duerig和Ning Ye对光度畸变的帮助。如果没有Chuck Rosenberg和Hartwig Adam的支持，我们的工作是不可能的。

 

工具书类

 

[1] 了解你的模因：我们需要更深一步。[http:y~2y~~2a知道你的模因。](http://knowyourmeme.com/memes/we-need-to-go-deeper)

 

[我们需要更深一步](http://knowyourmeme.com/memes/we-need-to-go-deeper). 访问：2014-0915。

 

[2] Sanjeev Arora、Aditya Bhaskara、Rong Ge和滕宇玛。学习一些深度表示的可证界限。CoRR，ABSUB~2Y13136334，2013。

¨

〔3〕	Umit V.C_atalyurek、Cevdet Aykanat和Bora Uc_ar。关于二维稀疏矩阵剖分：模型、方法和配方。暹罗J.SCI。计算机，32（2）：656 - 683，2010年2月。

 

〔4〕	杰弗里·迪安、格雷格·科拉多、拉杰特·蒙加、陈凯、马修·德文、马克·毛泽东、马克·朗扎托、马克·奥雷里奥·兰扎托、安德鲁·大人、保罗·塔克、柯扬、快克·V·勒和安德鲁·Y·吴。大规模分布式深网络。在P.Bartlett，F.c.n.Pereira，C.j.c.Burges，L.Bot-tou和K.q.Weinberger，编辑，神经信息处理系统进展25，第1232-1240页。2012。

 

〔5〕	Dumitru Erhan、Christian Szegedy、Alexander Toshev和Dragomir Anguelov。利用深度神经网络进行可扩展的OB检测。在计算机视觉和模式识别中，2014。CVPR 2014。IEEE会议，2014。

 

〔6〕	Ross B. Girshick、Jeff Donahue、Trevor Darrell和Jitendra Malik。丰富的特征层次，用于精确的对象检测和语义分割。在计算机视觉和模式识别中，2014。CVPR 2014。IEEE会议，2014。

 

〔7〕	Geoffrey E. Hinton，尼蒂斯里瓦斯塔瓦，Alex Krizhevsky，Ilya Sutskever和Ruslan Salakhut dinov。通过防止特征检测器的自适应适应来改进神经网络。CoRR，ABSUB~2Y27.0580，2012。

 

〔8〕	Andrew G. Howard。基于深度卷积神经网络的图像分类方法的改进CoRR，ABSUB~213135402，2013。

 

〔9〕	Alex Krizhevsky、Ilya Sutskever和Geoff Hinton。基于深度Con神经网络的IMANET分类在神经信息处理系统25的进展中，第1106页至第1114, 2012页。

 

〔10〕	Y. LeCun、B. Boser、J. S. Denker、D. Henderson、R. E. Howard、W·哈伯德和L. D. Jackel。反向传播技术在手写邮政编码识别中的应用神经计算机，1（4）：541—551，1989年12月。

 

〔11〕	Yann LeCun，列昂，Butou，Yoshua Bengio和Patrick Haffner。基于梯度的学习方法在文档识别中的应用IEEE会议录，86（11）：2278—2324, 1998。

 

〔12〕Min Lin、程前和水成艳。网络中的网络。CoRR，ABSUB~2Y131244，2013。

 

〔13〕	B. T. Polyak和A. B. Juditsky。用平均法加速随机逼近。暹罗J.控制OpTim.，30（4）：838 - 855，1992年7月。

 

〔14〕	Pierre Sermanet、David Eigen、向张、米迦勒、马蒂厄、Rob Fergus和Yann Le Cun。超卷积：利用卷积网络进行集成识别、定位和检测。CoRR，ABSUB~2Y13136229，2013。



 

十一



 

[15] Thomas Serre、Lior Wolf、Stanley M. Bileschi、Maximilian Riesenhuber和Tomaso Poggio。类皮质机制的鲁棒目标识别IEEE Trime.模式肛门。机器。因特尔，29（3）：411—426, 2007。

 

[16] 冯光松和Jack Dongarra。对具有1000个CPU核的共享内存多核心系统的矩阵计算进行扩展。在第二十八届ACM国际超级计算会议上，ICS 14，第333页-第342页，纽约，NY，美国，2014。ACM。

 

[17] 伊利亚苏特斯威夫，James Martens，George E. Dahl和Geoffrey E. Hinton。论深度学习中的初始化和动量的重要性。《第30届国际机器学习会议论文集》，ICML 2013，亚特兰大，GA，美国，2013年6月16日至21日，JMLR Proceedings第28卷，第1139-1147页。JMLR.ORG，2013。

 

[18] Christian Szegedy、Alexander Toshev和Dumitru Erhan。深度神经网络用于目标检测。在Christopher J.C.Burges，Leon_Bottou，Zoubin Ghahramani，Kilian Q.Weinberger，编辑，神经信息处理系统进展26：第27届神经信息处理系统年会。会议的议程于十二月5-8日，2013日，太浩湖，内华达州，美国，第2553页- 2561, 2013页。

 

[19] Alexander Toshev和Christian Szegedy。Deeppose：通过深度神经网络进行人体姿态估计。CoRR，ABSUB~21313465，2013。

 

[20] 科恩·E·A·范德桑德、贾斯珀R·R·UIJIN、Theo Gevers和阿诺德·M·斯穆尔德斯。分割作为对象识别的选择性搜索。2011年国际计算机视觉会议论文集，ICCV’11，第1879-1886页，美国华盛顿特区，2011年。IEEE计算机学会。

 

[21] Matthew D. Zeiler和Rob Fergus。可视化和理解卷积网络。在David J.Fleet，Tomas_Pajdla，Bernt Schiele和Tinne Tuytelaars，编辑，计算机视觉-ECCV 2014-第13届欧洲会议，瑞士苏黎世，2014年9月6日至12日，Pro-ceedings，第一部分，第8689卷，计算机科学讲稿，第818-833页。施普林格，2014。